\section{KD-Tree Accelerated Non-Local Means}

\label{sec:kdtree-nlm}

This section describes a possible improvement of the basic Non-Local Means algorithm that would improve its theoretical time complexity by using a KD-Tree data structure to speed up the finding of similar patches, at the cost of slight accuracy loss. While the theoretical time complexity of this approach is better, the naive algorithm is laughably simple to parallelize, meanwhile this approach does have some bottlenecks in the query phase that are harder to do so; as such, the actual runtime improvement may be less than expected. However, it is still an interesting approach to explore and implement, and can be used as a middle ground between the naive NLM and more heuristic approaches like Monte Carlo NLM.

More complex approaches that are based on this idea have been presented by Adams et al.\ in the SIGGRAPH 2009 paper~\cite{adams2009gaussian}, that explores the idea of a \emph{Gaussian KD-Tree}, and by Brox et al.~\cite{brox2008efficient} who introduced the notion of \emph{Cluster Trees}. The approach proposed by Adams et al., is a more advanced data structure that combines KD-Trees with Gaussian Mixture Models to further speed up the search for similar patches. This approach is more difficult to implement, but can provide even better performance, since the original authors implemented this using a GPU with CUDA support.

\subsection{Algorithm Description}

Unlike the Monte Carlo NLM algorithm, which randomly samples patches from the search window, this approach builds a KD-Tree from all the patches in the search window, and then queries it for the $K$ nearest neighbors of the current patch. This way, we can find the most similar patches more efficiently than by brute-force searching through all patches in the search window. More specifically, for each pixel $p$ in the image, we extract its patch $B(p, f)$ and consider a point in $\mathbb{R}^{(2f+1)^2}$ corresponding to the flattened patch. This $(2f+1)^2$-dimensional point is then inserted into the KD-Tree. After building the KD-Tree for all patches in the search window, we can query it for the $K$ nearest neighbors of the patch $B(p, f)$, and use these patches to compute the weights and denoise the pixel $p$. The weight computation and denoising steps remain the same as in the original NLM algorithm, but we only consider the $K$ nearest neighbors instead of all patches in the search window.

For RGB images, we would need to also consider the color channels, resulting in points in $\mathbb{R}^{3(2f+1)^2}$. However, as before, we will focus on grayscale images for simplicity.
